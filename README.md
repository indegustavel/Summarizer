# API de SumarizaÃ§Ã£o de Textos

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-green.svg)](https://fastapi.tiangolo.com/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

Uma API robusta e eficiente para sumarizaÃ§Ã£o de textos em portuguÃªs, desenvolvida com FastAPI e modelos de inteligÃªncia artificial avanÃ§ados.

## ğŸ“‹ VisÃ£o Geral

Esta API oferece dois mÃ©todos principais de sumarizaÃ§Ã£o:

- **SumarizaÃ§Ã£o Extrativa**: Seleciona as sentenÃ§as mais importantes do texto original usando algoritmos de processamento de linguagem natural
- **SumarizaÃ§Ã£o Abstrativa**: Gera novos textos concisos usando modelos de linguagem T5 treinados especificamente para tarefas de sumarizaÃ§Ã£o

A API Ã© capaz de processar textos de qualquer tamanho, utilizando tÃ©cnicas de chunking inteligente para textos longos, e oferece controle total sobre o comprimento dos resumos gerados.

## âœ¨ Funcionalidades Principais

### MÃ©todos de SumarizaÃ§Ã£o
- **Extrativo**: Baseado em seleÃ§Ã£o de sentenÃ§as-chave usando algoritmo LSA (Latent Semantic Analysis)
- **Abstrativo**: GeraÃ§Ã£o de texto usando modelo mT5 multilingual otimizado para portuguÃªs

### Controle de ParÃ¢metros
- `max_length`: Comprimento mÃ¡ximo do resumo (padrÃ£o: 150 caracteres, mÃ¡ximo: 1000)
- `min_length`: Comprimento mÃ­nimo do resumo (padrÃ£o: 30 caracteres, mÃ­nimo: 10)
- ValidaÃ§Ã£o automÃ¡tica de parÃ¢metros com mensagens de erro detalhadas

### Processamento AvanÃ§ado
- **Chunking Inteligente**: DivisÃ£o automÃ¡tica de textos longos em partes menores
- **Logging Detalhado**: Monitoramento completo de todas as operaÃ§Ãµes
- **Tratamento de Erros**: Captura e logging de exceÃ§Ãµes com informaÃ§Ãµes Ãºteis
- **ValidaÃ§Ã£o de Entrada**: VerificaÃ§Ã£o robusta de todos os parÃ¢metros

## ğŸš€ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### PrÃ©-requisitos

- **Python**: 3.8 ou superior
- **Git**: Para clonar o repositÃ³rio
- **Token do Hugging Face**: NecessÃ¡rio para acessar modelos (gratuito)

### InstalaÃ§Ã£o por Sistema Operacional

#### Windows

```bash
# 1. Clone o repositÃ³rio
git clone https://github.com/seu-usuario/api-sumarizacao-textos.git
cd api-sumarizacao-textos

# 2. Crie um ambiente virtual
python -m venv .venv1

# 3. Ative o ambiente virtual
.venv1\Scripts\activate

# 4. Instale as dependÃªncias
pip install -r requirements.txt

# 5. Configure o token do Hugging Face
# Crie um arquivo chamado API_HuggingFace no diretÃ³rio raiz
# Cole seu token do Hugging Face (obtenha em: https://huggingface.co/settings/tokens)
echo "hf_seu_token_aqui" > API_HuggingFace
```

#### Linux/macOS

```bash
# 1. Clone o repositÃ³rio
git clone https://github.com/seu-usuario/api-sumarizacao-textos.git
cd api-sumarizacao-textos

# 2. Crie um ambiente virtual
python3 -m venv .venv1

# 3. Ative o ambiente virtual
source .venv1/bin/activate

# 4. Instale as dependÃªncias
pip install -r requirements.txt

# 5. Configure o token do Hugging Face
echo "hf_seu_token_aqui" > API_HuggingFace
```

### DependÃªncias Principais

```txt
fastapi>=0.100.0
uvicorn>=0.20.0
pydantic>=2.0.0
transformers>=4.20.0
torch>=2.0.0
sumy>=0.11.0
nltk>=3.8.0
protobuf>=4.21.0
huggingface-hub>=0.15.0
```

### Executando Localmente

```bash
# Ative o ambiente virtual
.venv1\Scripts\activate  # Windows
# ou
source .venv1/bin/activate  # Linux/macOS

# Execute a API
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

A API estarÃ¡ disponÃ­vel em:
- **DocumentaÃ§Ã£o Interativa**: http://127.0.0.1:8000/docs
- **DocumentaÃ§Ã£o Alternativa**: http://127.0.0.1:8000/redoc
- **Endpoint Raiz**: http://127.0.0.1:8000/
- **VerificaÃ§Ã£o de SaÃºde**: http://127.0.0.1:8000/health

## ğŸ“– Exemplos de Uso

### Verificar Status da API

```bash
curl http://127.0.0.1:8000/
```

**Resposta:**
```json
{
  "message": "Bem-vindo Ã  API de SumarizaÃ§Ã£o de Textos!",
  "docs": "/docs",
  "methods": ["extractive", "abstractive"],
  "version": "2.0.0"
}
```

### Verificar SaÃºde do Sistema

```bash
curl http://127.0.0.1:8000/health
```

**Resposta:**
```json
{
  "status": "healthy",
  "timestamp": "2025-09-04T20:44:11.628Z",
  "version": "2.0.0",
  "model": "csebuetnlp/mT5_multilingual_XLSum"
}
```

### SumarizaÃ§Ã£o Extrativa

```bash
curl -X POST "http://127.0.0.1:8000/summarize" \
  -H "Content-Type: application/json" \
  -d '{
    "text": "A inteligÃªncia artificial estÃ¡ revolucionando diversos setores da sociedade. Desde o diagnÃ³stico mÃ©dico atÃ© a anÃ¡lise financeira, os algoritmos de IA demonstram capacidades impressionantes. No entanto, Ã© fundamental garantir que seu desenvolvimento seja Ã©tico e responsÃ¡vel.",
    "method": "extractive",
    "max_length": 200,
    "min_length": 50
  }'
```

### SumarizaÃ§Ã£o Abstrativa

```bash
curl -X POST "http://127.0.0.1:8000/summarize" \
  -H "Content-Type: application/json" \
  -d '{
    "text": "A inteligÃªncia artificial estÃ¡ revolucionando diversos setores da sociedade. Desde o diagnÃ³stico mÃ©dico atÃ© a anÃ¡lise financeira, os algoritmos de IA demonstram capacidades impressionantes. No entanto, Ã© fundamental garantir que seu desenvolvimento seja Ã©tico e responsÃ¡vel.",
    "method": "abstractive",
    "max_length": 150,
    "min_length": 30
  }'
```

### Exemplo com Python

```python
import requests

# ConfiguraÃ§Ã£o da requisiÃ§Ã£o
url = "http://127.0.0.1:8000/summarize"
payload = {
    "text": "Texto longo que vocÃª deseja resumir...",
    "method": "abstractive",
    "max_length": 200,
    "min_length": 50
}

# Fazendo a requisiÃ§Ã£o
response = requests.post(url, json=payload)
result = response.json()

print("Resumo:", result["summary"])
```

## ğŸ“š DocumentaÃ§Ã£o da API

### Modelos de Dados

#### TextInput
Modelo para entrada de dados de sumarizaÃ§Ã£o.

```python
class TextInput(BaseModel):
    text: str                           # Texto a ser sumarizado (obrigatÃ³rio)
    method: str = "extractive"          # MÃ©todo: 'extractive' ou 'abstractive'
    max_length: int = 150              # Comprimento mÃ¡ximo em caracteres
    min_length: int = 30               # Comprimento mÃ­nimo em caracteres
```

**Exemplo:**
```json
{
  "text": "A inteligÃªncia artificial estÃ¡ transformando o mundo...",
  "method": "abstractive",
  "max_length": 200,
  "min_length": 50
}
```

#### SummaryOutput
Modelo para saÃ­da de dados de sumarizaÃ§Ã£o.

```python
class SummaryOutput(BaseModel):
    summary: str  # Texto resumido gerado
```

**Exemplo:**
```json
{
  "summary": "A IA estÃ¡ revolucionando diversos setores, desde medicina atÃ© finanÃ§as, mas seu desenvolvimento deve ser Ã©tico."
}
```

### Endpoints

#### GET /
Retorna informaÃ§Ãµes bÃ¡sicas sobre a API.

- **URL**: `/`
- **MÃ©todo**: GET
- **Resposta**: InformaÃ§Ãµes da API

#### GET /health
Verifica o status de saÃºde da API.

- **URL**: `/health`
- **MÃ©todo**: GET
- **Resposta**: Status do sistema

#### POST /summarize
Realiza a sumarizaÃ§Ã£o do texto fornecido.

- **URL**: `/summarize`
- **MÃ©todo**: POST
- **Corpo**: Objeto TextInput
- **Resposta**: Objeto SummaryOutput

**CÃ³digos de Status:**
- `200`: Sucesso
- `400`: Erro de validaÃ§Ã£o (parÃ¢metros invÃ¡lidos)
- `500`: Erro interno do servidor

## ğŸ”§ Detalhes TÃ©cnicos

### MÃ©todo Extrativo

1. **PrÃ©-processamento**: TokenizaÃ§Ã£o e anÃ¡lise linguÃ­stica usando NLTK
2. **AnÃ¡lise de SentenÃ§as**: ExtraÃ§Ã£o de features das sentenÃ§as (comprimento, posiÃ§Ã£o, palavras-chave)
3. **PontuaÃ§Ã£o LSA**: AplicaÃ§Ã£o do algoritmo Latent Semantic Analysis para identificar sentenÃ§as mais relevantes
4. **SeleÃ§Ã£o**: Escolha das N sentenÃ§as com maior pontuaÃ§Ã£o
5. **PÃ³s-processamento**: Ajuste do comprimento baseado nos parÃ¢metros `max_length` e `min_length`

**Vantagens:**
- Preserva o texto original
- Mais rÃ¡pido e eficiente
- Menos propenso a erros factuais

### MÃ©todo Abstrativo

1. **PrÃ©-processamento**: AdiÃ§Ã£o do prefixo "summarize: " para orientar o modelo T5
2. **TokenizaÃ§Ã£o**: ConversÃ£o do texto em tokens usando o tokenizer do mT5
3. **Chunking (se necessÃ¡rio)**: DivisÃ£o em partes menores se o texto exceder 512 tokens
4. **GeraÃ§Ã£o**: Uso do pipeline de sumarizaÃ§Ã£o com parÃ¢metros otimizados:
   - `temperature=0.3`: Controle de aleatoriedade
   - `top_p=0.9`: Nucleus sampling
   - `top_k=50`: LimitaÃ§Ã£o de candidatos
   - `num_beams=4`: Busca por feixe para qualidade
   - `repetition_penalty=1.2`: PenalizaÃ§Ã£o de repetiÃ§Ãµes
5. **PÃ³s-processamento**: ValidaÃ§Ã£o do comprimento e ajuste se necessÃ¡rio

**ParÃ¢metros AvanÃ§ados:**
- **Beam Search**: Explora mÃºltiplas possibilidades de geraÃ§Ã£o para encontrar o melhor resumo
- **Repetition Penalty**: Evita frases repetidas no resumo
- **Length Control**: Garante que o resumo respeite os limites especificados

### ValidaÃ§Ãµes e Logging

**ValidaÃ§Ãµes Implementadas:**
- VerificaÃ§Ã£o de texto vazio
- ValidaÃ§Ã£o de `max_length > min_length`
- Limites de `max_length` (mÃ¡ximo 1000)
- Limites de `min_length` (mÃ­nimo 10)

**Sistema de Logging:**
- Logs estruturados com timestamps
- NÃ­veis: INFO, WARNING, ERROR
- InformaÃ§Ãµes sobre processamento de chunks
- Valores de parÃ¢metros utilizados
- Tempos de processamento
- Detalhes de erros ocorridos

### Processamento de Textos Longos

Para textos que excedem o limite do modelo (512 tokens):

1. **DivisÃ£o Inteligente**: Prioriza quebras por sentenÃ§as para manter coerÃªncia
2. **Fallback por Tokens**: Se a divisÃ£o por sentenÃ§as falhar, divide por tokens
3. **DistribuiÃ§Ã£o de Comprimento**: Aloca o `max_length` entre os chunks
4. **CombinaÃ§Ã£o**: Junta os resumos parciais
5. **Resumo Final**: Se necessÃ¡rio, gera um resumo do resumo combinado

### Diretrizes de ContribuiÃ§Ã£o
- Siga o estilo de cÃ³digo PEP 8
- Adicione testes para novas funcionalidades
- Atualize a documentaÃ§Ã£o conforme necessÃ¡rio
- Mantenha compatibilidade com versÃµes anteriores

## ğŸ“ Suporte

Para suporte ou dÃºvidas:
- Abra uma issue no GitHub
- Consulte a documentaÃ§Ã£o em `/docs`
- Verifique os logs da aplicaÃ§Ã£o para diagnÃ³stico

## ğŸ”„ Changelog

### VersÃ£o 2.0.0
- âœ¨ ReformulaÃ§Ã£o completa do mÃ©todo abstrativo
- ğŸš€ AdiÃ§Ã£o de controle de parÃ¢metros `max_length` e `min_length`
- ğŸ“Š ImplementaÃ§Ã£o de logging detalhado
- ğŸ”§ Chunking inteligente para textos longos
- ğŸ›¡ï¸ ValidaÃ§Ã£o robusta de entrada
- ğŸ“š DocumentaÃ§Ã£o aprimorada

### VersÃ£o 1.0.0
- âœ… ImplementaÃ§Ã£o bÃ¡sica com mÃ©todos extrativo e abstrativo
- âœ… API funcional com FastAPI
- âœ… IntegraÃ§Ã£o com modelos Hugging Face

---


**Desenvolvido com â¤ï¸ usando FastAPI e Transformers**
